{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16ea003f",
   "metadata": {},
   "source": [
    "# **Learning Rate Sensitivity**\n",
    "\n",
    "This experiment evaluates how step size influences convergence speed\n",
    "and final optimization quality. The focus is on loss behavior,\n",
    "not just final accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "606adb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(current_dir, \"..\")) \n",
    "\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c4837d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from src.model import LogisticRegression\n",
    "from src.preprocessing import StandardScaler\n",
    "from src.plotting import handle_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1020526c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_breast_cancer()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4178f177",
   "metadata": {},
   "source": [
    "**Learning rates are tested under identical conditions to isolate the effect of step size.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ec47545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Loss: 0.693147\n",
      "Epoch 100 | Loss: 0.540657\n",
      "Epoch 200 | Loss: 0.452971\n",
      "Epoch 300 | Loss: 0.396392\n",
      "Epoch 400 | Loss: 0.356609\n",
      "Epoch 500 | Loss: 0.326897\n",
      "Epoch 600 | Loss: 0.303715\n",
      "Epoch 700 | Loss: 0.285022\n",
      "Epoch 800 | Loss: 0.269557\n",
      "Epoch 900 | Loss: 0.256500\n",
      "Epoch 0 | Loss: 0.693147\n",
      "Epoch 100 | Loss: 0.244663\n",
      "Epoch 200 | Loss: 0.182222\n",
      "Epoch 300 | Loss: 0.153932\n",
      "Epoch 400 | Loss: 0.137189\n",
      "Epoch 500 | Loss: 0.125909\n",
      "Epoch 600 | Loss: 0.117686\n",
      "Epoch 700 | Loss: 0.111363\n",
      "Epoch 800 | Loss: 0.106313\n",
      "Epoch 900 | Loss: 0.102163\n",
      "Epoch 0 | Loss: 0.693147\n",
      "Epoch 100 | Loss: 0.098281\n",
      "Epoch 200 | Loss: 0.080073\n",
      "Epoch 300 | Loss: 0.072221\n",
      "Epoch 400 | Loss: 0.067596\n",
      "Epoch 500 | Loss: 0.064452\n",
      "Epoch 600 | Loss: 0.062130\n",
      "Epoch 700 | Loss: 0.060320\n",
      "Epoch 800 | Loss: 0.058856\n",
      "Epoch 900 | Loss: 0.057638\n"
     ]
    }
   ],
   "source": [
    "learning_rates = [0.001, 0.01, 0.1]\n",
    "histories = {}\n",
    "\n",
    "for lr in learning_rates:\n",
    "    model = LogisticRegression(learning_rate=lr, n_iters=1000)\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    histories[lr] = model.loss_history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2731b65",
   "metadata": {},
   "source": [
    "**Loss curves are compared to assess stability and convergence rate.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62cc1a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_PLOTS = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f6b3890",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "\n",
    "for lr, history in histories.items():\n",
    "    plt.plot(history, label=f\"lr={lr}\")\n",
    "\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Learning Rate Sensitivity\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "handle_plot(filename=\"learning_rate_comparison.png\",\n",
    "            save_plots=SAVE_PLOTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175cfd83",
   "metadata": {},
   "source": [
    "**A higher learning rate converges faster in this setup without instability.**\n",
    "\n",
    "**This behavior is dataset-dependent and enabled by proper scaling.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
